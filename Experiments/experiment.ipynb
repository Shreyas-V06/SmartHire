{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_api_key=os.getenv('GOOGLE_API_KEY') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings,StorageContext,load_index_from_storage,VectorStoreIndex,SimpleDirectoryReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shreyas\\Desktop\\SmartHire\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.llms.gemini import Gemini\n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=google_api_key) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=SimpleDirectoryReader(r\"C:\\Users\\Shreyas\\Desktop\\SmartHire\\experiments\\data\").load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Gemini(models='gemini-1.5-pro',api_key=google_api_key)\n",
    "gemini_embed_model=GeminiEmbedding(model_name='models/text-embedding-004')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = model \n",
    "Settings.embed_model=gemini_embed_model\n",
    "Settings.chunk_size=800\n",
    "Settings.chunk_overlap=20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=VectorStoreIndex.from_documents(doc)\n",
    "index.storage_context.persist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter=\"Knowledge in ML\" \n",
    "prompt= f\"\"\"You are an AI system designed to extract only the most relevant sections from a resume based on a given parameter. \n",
    "Focus on details from Work Experience, Skills, Education, Certifications, Projects, or Achievements \n",
    "\n",
    "Ignore personal details, details about education, unrelated experience, and generic skills.\n",
    "Do not summarize the document, display it as it is.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software Developer Intern, CodeWorks Inc., Summer 2023 June 2022 – Present \n",
      "● Developed backend services using Java and Spring Boot \n",
      "● Collaborated on database design and SQL query optimization \n",
      "● Integrated REST APIs for web applications \n",
      "\n",
      "Programming Languages: Java, Python, C++  \n",
      "Web Development: HTML, CSS, JavaScript (ES6)  \n",
      "Frameworks/Technologies: Spring Boot, Flask, Docker, Kubernetes \n",
      "Database Management: SQL, PostgreSQL  \n",
      "Version Control: Git, GitHub \n",
      "\n",
      "Distributed Chat Application: \n",
      "• Developed a real-time chat application using Java, WebSocket, and Spring Boot. \n",
      "• Implemented a scalable server architecture supporting thousands of concurrent users. \n",
      "• Integrated a NoSQL database (MongoDB) for persistent message storage. \n",
      "Smart Scheduler: \n",
      "• Built a web-based scheduling application using Python (Flask) and JavaScript. \n",
      "• Utilized machine learning algorithms (scikit-learn) to predict optimal task timings. \n",
      "• Designed a responsive user interface with HTML, CSS, and Bootstrap. \n",
      "Portfolio Website: \n",
      "• Created a responsive website to showcase projects and technical achievements. \n",
      "• Developed using HTML, CSS, JavaScript, and integrated the GitHub API for live project feeds. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retriever = index.as_query_engine()\n",
    "answer=retriever.query(prompt)\n",
    "print(answer.response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f\"\"\"\n",
    "    You are an AI system designed to assist in resume screening. \n",
    "    Extract all the technical skills, technologies, programming languages, frameworks, \n",
    "    tools, and libraries from the given description. \n",
    "\n",
    "    The list should be very exhaustive and should not miss any skills, neither should it include any \n",
    "    skills which are not present in the description.\n",
    "\n",
    "\n",
    "Skills Description:\n",
    "{answer.response}\n",
    "\n",
    "Output format: Comma separated \n",
    "Skill1,Skill2,Skill3, ...,SkillN \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.complete(prompt1)\n",
    "skill_list = [skill.strip() for skill in response.text.split(\",\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# # Load a pre-trained sentence transformer model\n",
    "# sentence_transformer_model = SentenceTransformer('BAAI/bge-large-en-v1.5')\n",
    "\n",
    "# # Convert \"Machine Learning\" and each skill to embeddings\n",
    "# target_skill = \"Machine Learning\"\n",
    "# target_embedding = sentence_transformer_model.encode([target_skill])[0]\n",
    "\n",
    "# # Generate embeddings for each skill and calculate similarity\n",
    "# similarities = []\n",
    "# for skill in skill_list:\n",
    "#     skill_embedding = sentence_transformer_model.encode([skill])[0]\n",
    "#     similarity = np.dot(target_embedding, skill_embedding) / (np.linalg.norm(target_embedding) * np.linalg.norm(skill_embedding))\n",
    "#     similarities.append((skill, similarity))\n",
    "\n",
    "# # Sort skills by similarity score and print\n",
    "# similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "# print(\"Similarity scores with 'Machine Learning':\")\n",
    "# for skill, score in similarities:\n",
    "#     print(f\"{skill}: {score:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores with 'Machine Learning':\n",
      "Huggingface: 0.5325\n",
      "Mongoose: 0.6081\n"
     ]
    }
   ],
   "source": [
    "# Define the skills to compare\n",
    "skills_to_compare = [\"Huggingface\", \"Mongoose\"]\n",
    "\n",
    "# Generate embeddings for the target skills\n",
    "target_embeddings = sentence_transformer_model.encode(skills_to_compare)\n",
    "\n",
    "# Calculate similarity with \"Machine Learning\"\n",
    "ml_embedding = sentence_transformer_model.encode([\"Machine Learning\"])[0]\n",
    "\n",
    "print(\"Similarity scores with 'Machine Learning':\")\n",
    "for skill, embedding in zip(skills_to_compare, target_embeddings):\n",
    "    similarity = np.dot(ml_embedding, embedding) / (np.linalg.norm(ml_embedding) * np.linalg.norm(embedding))\n",
    "    print(f\"{skill}: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranked Skills:\n",
      "PyTorch: 0.1164\n",
      "TensorFlow: 0.1149\n",
      "C++: 0.1121\n",
      "Python: 0.1105\n",
      "LangChain: 0.1104\n",
      "React: 0.1103\n",
      "SQL: 0.1100\n",
      ": 0.1080\n",
      "Huggingface: 0.1075\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
